{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.autograd\n",
    "import h5py\n",
    "import torch.optim as optim\n",
    "import scipy.io\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "from enum import Enum\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.utils.data.distributed\n",
    "#import horovod.torch as hvd\n",
    "from tensorboardX import SummaryWriter\n",
    "from argparse import ArgumentParser\n",
    "import os\n",
    "import sys\n",
    "import pathlib\n",
    "sys.path.append('/Users/juanesteban/PINNs') \n",
    "from Schrodinger_2D.SchrodingerBalancedECDataset import SchrodingerEquationDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--identifier IDENTIFIER]\n",
      "                             [--batchsize BATCHSIZE] [--numbatches NUMBATCHES]\n",
      "                             [--initsize INITSIZE] [--numlayers NUMLAYERS]\n",
      "                             [--numfeatures NUMFEATURES]\n",
      "                             [--epochssolution EPOCHSSOLUTION]\n",
      "                             [--epochsPDE EPOCHSPDE] [--energyloss ENERGYLOSS]\n",
      "                             [--pretraining PRETRAINING] [--alpha ALPHA]\n",
      "                             [--lhs LHS]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f /Users/juanesteban/Library/Jupyter/runtime/kernel-e14686cc-d4bb-4294-acdd-396aa912685d.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/juanesteban/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3304: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class SchrodingerNet(nn.Module):\n",
    "    def __init__(self, numLayers, numFeatures, lb, ub, samplingX, samplingY, activation=torch.tanh):\n",
    "        \"\"\"\n",
    "        This function creates the components of the Neural Network and saves the datasets\n",
    "        :param x0: Position x at time zero\n",
    "        :param u0: Real Part of the solution at time 0 at position x\n",
    "        :param v0: Imaginary Part of the solution at time 0 at position x\n",
    "        :param tb: Time Boundary\n",
    "        :param X_f: Training Data for partial differential equation\n",
    "        :param layers: Describes the structure of Neural Network\n",
    "        :param lb: Value of the lower bound in space\n",
    "        :param ub: Value of the upper bound in space\n",
    "        \"\"\"\n",
    "        torch.manual_seed(1234)\n",
    "        super(SchrodingerNet, self).__init__()\n",
    "        self.numLayers = numLayers\n",
    "        self.numFeatures = numFeatures\n",
    "        self.lin_layers = nn.ModuleList()\n",
    "        self.activation = activation\n",
    "        self.lb = torch.Tensor(lb).float().cuda()\n",
    "        self.ub = torch.Tensor(ub).float().cuda()\n",
    "        \n",
    "        #calculate matrix for trepze rule \n",
    "        #matrix construction follows from : http://mathfaculty.fullerton.edu/mathews/n2003/SimpsonsRule2DMod.html\n",
    "        W = np.zeros((samplingX, samplingY))\n",
    "        W[0, 0] = 1\n",
    "        W[0, samplingY - 1] = 1\n",
    "        W[samplingX - 1, samplingY - 1] = 1\n",
    "        W[samplingX - 1, 0] = 1\n",
    "\n",
    "        for idx in range(1, samplingX - 1):\n",
    "            W[idx, 0] = 2\n",
    "            W[idx, samplingY - 1] = 2\n",
    "\n",
    "        for idx in range(1, samplingY - 1):\n",
    "            W[0, idx] = 2\n",
    "            W[samplingX - 1, idx] = 2\n",
    "\n",
    "        for i in range(1, samplingX - 1):\n",
    "            for j in range(1, samplingY - 1):\n",
    "                W[i, j] = 4\n",
    "\n",
    "        W = W.reshape(-1)\n",
    "        self.W = torch.Tensor(W).float().cuda()\n",
    "\n",
    "        # building the neural network\n",
    "        self.init_layers()\n",
    "\n",
    "        # Creating Weight Matrix for energy conservation mechanism\n",
    "\n",
    "    def init_layers(self):\n",
    "        \"\"\"\n",
    "        This function creates the torch layers and initialize them with xavier\n",
    "        :param self:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        self.lin_layers.append(nn.Linear(3, self.numFeatures))\n",
    "        for _ in range(self.numLayers):\n",
    "            inFeatures = self.numFeatures\n",
    "            self.lin_layers.append(nn.Linear(inFeatures, self.numFeatures))\n",
    "        self.lin_layers.append(nn.Linear(inFeatures, 2))\n",
    "\n",
    "        for m in self.lin_layers:\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_normal_(m.weight)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def net_uv(self, x, y, t):\n",
    "        \"\"\"\n",
    "        Function that calculates the nn output at postion (x,y) at time t\n",
    "        :param x: position\n",
    "        :param t: time\n",
    "        :return: Approximated solutions and their gradients\n",
    "        \"\"\"\n",
    "\n",
    "        #torch.cuda.empty_cache()\n",
    "        dim = x.shape[0] #defines the shape of the gradient\n",
    "\n",
    "        # save input in variabeles is necessary for gradient calculation\n",
    "        x = Variable(x, requires_grad=True).cuda()\n",
    "        y = Variable(y, requires_grad=True).cuda()\n",
    "        t = Variable(t, requires_grad=True).cuda()\n",
    "\n",
    "        X = torch.stack([x, y, t], 1)\n",
    "\n",
    "        UV = self.forward(X)\n",
    "        u = UV[:, 0]\n",
    "        v = UV[:, 1]\n",
    "        grads = torch.ones([dim]).cuda()\n",
    "\n",
    "        # huge change to the tensorflow implementation this function returns all neccessary gradients\n",
    "        J_U = torch.autograd.grad(u,[x,y,t], create_graph=True, grad_outputs=grads)\n",
    "        J_V = torch.autograd.grad(v,[x,y,t], create_graph=True, grad_outputs=grads)\n",
    "    \n",
    "        u_x = J_U[0].reshape([dim])\n",
    "        u_y = J_U[1].reshape([dim])\n",
    "        u_t = J_U[2].reshape([dim])\n",
    "\n",
    "        v_x = J_V[0].reshape([dim])\n",
    "        v_y = J_V[1].reshape([dim])\n",
    "        v_t = J_V[2].reshape([dim])\n",
    "\n",
    "        u_xx = torch.autograd.grad(u_x, x, create_graph=True, grad_outputs=grads)[0]\n",
    "        v_xx = torch.autograd.grad(v_x, x, create_graph=True, grad_outputs=grads)[0]\n",
    "\n",
    "        u_yy = torch.autograd.grad(u_y, y, create_graph=True, grad_outputs=grads)[0]\n",
    "        v_yy = torch.autograd.grad(v_y, y, create_graph=True, grad_outputs=grads)[0]\n",
    "\n",
    "        u_xx = u_xx.reshape([dim])\n",
    "        v_xx = v_xx.reshape([dim])\n",
    "        u_yy = u_yy.reshape([dim])\n",
    "        v_yy = v_yy.reshape([dim])\n",
    "\n",
    "        return u, v, u_yy, v_yy, u_xx, v_xx, u_t, v_t\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        This function is the forward of a simple multilayer perceptron\n",
    "        \"\"\"\n",
    "        #normalize input in range between -1 and 1 for better training convergence\n",
    "        x = 2.0 * (x - self.lb) / (self.ub - self.lb) - 1.0\n",
    "        for i in range(0, len(self.lin_layers) - 2):\n",
    "            x = self.lin_layers[i](x)\n",
    "            x = self.activation(x)\n",
    "            # x = torch.sin(x)\n",
    "            # x = F.tanh(x)\n",
    "        x = self.lin_layers[-1](x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def net_pde(self, x, y, t, omega=1.):\n",
    "        \"\"\"\n",
    "        Calculates the quality of the pde estimation\n",
    "        :param x postion x\n",
    "        :param t time t\n",
    "        :param omega frequency of the harmonic oscillator \n",
    "        \"\"\"\n",
    "        #get predicted solution and the gradients \n",
    "        u, v, u_yy, v_yy, u_xx, v_xx, u_t, v_t = self.net_uv(x, y, t)\n",
    "        x = x.view(-1)\n",
    "        y = y.view(-1)\n",
    "\n",
    "        #calculate loss for real and imaginary part seperatly \n",
    "        # fu is the real part of the schrodinger equation\n",
    "        f_u = -1 * u_t - 0.5 * v_xx - 0.5 * v_yy + omega* 0.5 * (x ** 2) * v + omega * 0.5 *  (y ** 2) * v\n",
    "        # fv is the imaginary part of the schrodinger equation \n",
    "        f_v = -1 * v_t + 0.5 * u_xx + 0.5 * u_yy - omega* 0.5 * (x ** 2) * u - omega * 0.5 * (y ** 2) * u\n",
    "        return u, v, f_u, f_v\n",
    "\n",
    "    def solution_loss(self, x, y, t, u0, v0):\n",
    "        \"\"\"\n",
    "        Supervised loss for training the initial condition \n",
    "        \"\"\"\n",
    "        x = x.view(-1)\n",
    "        y = y.view(-1)\n",
    "        t = t.view(-1)\n",
    "\n",
    "        inputX = torch.stack([x, y, t], 1)\n",
    "        UV = self.forward(inputX)\n",
    "        u = UV[:, 0]\n",
    "        v = UV[:, 1]\n",
    "\n",
    "        u0 = u0.view(-1)\n",
    "        v0 = v0.view(-1)\n",
    "\n",
    "        loss = torch.mean((u0 - u) ** 2) + torch.mean(v ** 2)\n",
    "        return loss\n",
    "\n",
    "  \n",
    "\n",
    "    def ec_pde_loss(self, x0, y0, t0, u0, v0, xf, yf, tf, xe, ye, te, c, samplingX, samplingY,activateEnergyLoss=True, alpha=1.):\n",
    "    \n",
    "        #reshape all inputs into correct shape \n",
    "        x0 = x0.view(-1)\n",
    "        y0 = y0.view(-1)\n",
    "        t0 = t0.view(-1)\n",
    "        xf = xf.view(-1)\n",
    "        yf = yf.view(-1)\n",
    "        tf = tf.view(-1)\n",
    "        xe = xe.view(-1)\n",
    "        ye = ye.view(-1)\n",
    "        te = te.view(-1)\n",
    "\n",
    "        n0 = x0.shape[0]\n",
    "        nf = xf.shape[0]\n",
    "\n",
    "        inputX = torch.cat([x0, xf, xe])\n",
    "        inputY = torch.cat([y0, yf, ye])\n",
    "        inputT = torch.cat([t0, tf, te])\n",
    "        \n",
    "        \n",
    "\n",
    "        u, v, f_u, f_v = self.net_pde(inputX, inputY, inputT)\n",
    "\n",
    "        solU = u[:n0]\n",
    "        solV = v[:n0]\n",
    "\n",
    "        eU = u[n0 + nf:]\n",
    "        eV = v[n0 + nf:]\n",
    "        eH = eU ** 2 + eV ** 2\n",
    "\n",
    "        lowerX = self.lb[0]\n",
    "        higherX = self.ub[0]\n",
    "\n",
    "        lowerY = self.lb[1]\n",
    "        higherY = self.ub[1]\n",
    "\n",
    "        disX = (higherX - lowerX) / samplingX\n",
    "        disY = (higherY - lowerY) / samplingY\n",
    "\n",
    "        u0 = u0.view(-1)\n",
    "        v0 = v0.view(-1)\n",
    "        integral = 0.25 * disX * disY * torch.sum(eH * self.W)\n",
    "        # calculte integral over field for energy conservation\n",
    "        eLoss = (integral - c) ** 2\n",
    "\n",
    "        pdeLoss = alpha * torch.mean((solU - u0) ** 2) + \\\n",
    "                  alpha * torch.mean((solV - v0) ** 2) + \\\n",
    "                  torch.mean(f_u ** 2) + \\\n",
    "                  torch.mean(f_v ** 2)\n",
    "        if activateEnergyLoss:\n",
    "            pdeLoss = pdeLoss + eLoss\n",
    "\n",
    "        if epoch % 30 == 0:\n",
    "            #write into tensorboard\n",
    "            if log_writer:\n",
    "                log_writer.add_scalar('Solution U', torch.mean((solU - u0) ** 2), epoch)\n",
    "                log_writer.add_scalar('Solution V', torch.mean((solV - v0) ** 2), epoch)\n",
    "                log_writer.add_scalar('Real PDE', torch.mean(f_u ** 2), epoch)\n",
    "                log_writer.add_scalar('Imaginary PDE', torch.mean(f_v ** 2), epoch)\n",
    "                log_writer.add_scalar('Energy Loss', eLoss, epoch)\n",
    "                log_writer.add_scalar('PDE Loss', pdeLoss, epoch)\n",
    "                log_writer.add_scalar('Integral', integral, epoch)\n",
    "\n",
    "        return pdeLoss\n",
    "\n",
    "\n",
    "def writeIntermediateState(timeStep, model, epoch, nx, ny, fileWriter,csystem):\n",
    "    \"\"\"\n",
    "    Functions that write intermediate solutions to tensorboard\n",
    "    \"\"\"\n",
    "    if fileWriter:\n",
    "        x, y, t = SchrodingerEquationDataset.getInput(timeStep,csystem)\n",
    "        x = torch.Tensor(x).float().cuda()\n",
    "        y = torch.Tensor(y).float().cuda()\n",
    "        t = torch.Tensor(t).float().cuda()\n",
    "\n",
    "        inputX = torch.stack([x, y, t], 1)\n",
    "        UV = model.forward(inputX).detach().cpu().numpy()\n",
    "\n",
    "        u = UV[:, 0].reshape((nx, ny))\n",
    "        v = UV[:, 1].reshape((nx, ny))\n",
    "\n",
    "        h = u ** 2 + v ** 2\n",
    "\n",
    "        fig = plt.figure()\n",
    "        plt.imshow(u, cmap='jet')\n",
    "        plt.colorbar()\n",
    "        fileWriter.add_figure('Real_' + str(timeStep), fig, epoch)\n",
    "        plt.close(fig)\n",
    "\n",
    "        fig = plt.figure()\n",
    "        plt.imshow(v, cmap='jet')\n",
    "        plt.colorbar()\n",
    "        fileWriter.add_figure('Imaginary_' + str(timeStep), fig, epoch)\n",
    "        plt.close(fig)\n",
    "\n",
    "        fig = plt.figure()\n",
    "        plt.imshow(h, cmap='jet')\n",
    "        plt.colorbar()\n",
    "        fileWriter.add_figure('Norm_' + str(timeStep), fig, epoch)\n",
    "        plt.close(fig)\n",
    "\n",
    "\n",
    "def valLoss(model, timeStep, csystem):\n",
    "    \"\"\"\n",
    "    The validation loss is the MSE between predicted and correct solution.\n",
    "    The loss is calculated seperatly for real and imaginary part \n",
    "    \"\"\"\n",
    "    x, y, t = SchrodingerEquationDataset.getInput(timeStep,csystem)\n",
    "    x = torch.Tensor(x).float().cuda()\n",
    "    y = torch.Tensor(y).float().cuda()\n",
    "    t = torch.Tensor(t).float().cuda()\n",
    "\n",
    "    inputX = torch.stack([x, y, t], 1)\n",
    "    UV = model.forward(inputX).detach().cpu().numpy()\n",
    "    uPred = UV[:, 0]\n",
    "    vPred = UV[:, 1]\n",
    "\n",
    "    # load label data\n",
    "    uVal, vVal = SchrodingerEquationDataset.loadFrame(pData, timeStep)\n",
    "    uVal = np.array(uVal)\n",
    "    vVal = np.array(vVal)\n",
    "\n",
    "    valLoss = np.mean((uVal - uPred) ** 2) + np.mean((vVal - vPred) ** 2)\n",
    "    return valLoss\n",
    "\n",
    "\n",
    "def writeValidationLoss(model, writer, timeStep, epoch, csystem):\n",
    "    if writer:\n",
    "        loss = valLoss(model, timeStep,csystem)\n",
    "        writer.add_scalar(\"ValidationLoss_\" + str(timeStep), loss, epoch)\n",
    "\n",
    "\n",
    "def save_checkpoint(model, optimizer, path, epoch):\n",
    "    state = {\n",
    "        'model': model.state_dict(),\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "    }\n",
    "    torch.save(state, path + 'model_' + str(epoch))\n",
    "\n",
    "\n",
    "def load_checkpoint(model, optimizer, path):\n",
    "    checkpoint = torch.load(path)\n",
    "    model.load_state_dict(checkpoint['model'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # Initialize Horovod\n",
    "    hvd.init()\n",
    "\n",
    "    # Pin GPU to be used to process local rank (one GPU per process)\n",
    "    torch.cuda.set_device(hvd.local_rank())\n",
    "\n",
    "    # static parameter\n",
    "    nx = 200\n",
    "    ny = 200\n",
    "    nt = 1000\n",
    "    xmin = -3\n",
    "    xmax = 3\n",
    "    ymin = -3\n",
    "    ymax = 3\n",
    "    dt = 0.001\n",
    "    numOfEnergySamplingPointsX = 100\n",
    "    numOfEnergySamplingPointsY = 100\n",
    "\n",
    "    coordinateSystem = {\"x_lb\": xmin, \"x_ub\": xmax, \"y_lb\": ymin, \"y_ub\" : ymax, \"nx\": nx , \"ny\": ny, \"nt\": nt, \"dt\": dt}\n",
    "\n",
    "    pData = '/projects/p_electron/stiller/schrodinger/data/schrodinger_reduced_3/'\n",
    "\n",
    "    batchSizeInit = 2500  #for the balanced dataset is not needed\n",
    "\n",
    "    parser = ArgumentParser()\n",
    "    parser.add_argument(\"--identifier\", dest=\"identifier\", type=str)\n",
    "    parser.add_argument(\"--batchsize\", dest=\"batchsize\", type=int)\n",
    "    parser.add_argument(\"--numbatches\", dest=\"numBatches\", type=int)\n",
    "    parser.add_argument(\"--initsize\", dest=\"initSize\", type=int)\n",
    "    parser.add_argument(\"--numlayers\", dest=\"numLayers\", type=int)\n",
    "    parser.add_argument(\"--numfeatures\", dest=\"numFeatures\", type=int)\n",
    "    parser.add_argument(\"--epochssolution\", dest=\"epochsSolution\", type=int)\n",
    "    parser.add_argument(\"--epochsPDE\", dest=\"epochsPDE\", type=int)\n",
    "    parser.add_argument(\"--energyloss\", dest=\"energyLoss\",type=int)\n",
    "    parser.add_argument(\"--pretraining\", dest=\"pretraining\", type=int)\n",
    "    parser.add_argument(\"--alpha\",dest=\"alpha\",type=float)\n",
    "    parser.add_argument(\"--lhs\",dest=\"lhs\",type=int)\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    if hvd.rank() == 0: \n",
    "        print(\"-\" * 10 + \"-\" * len(args.identifier) + \"-\" * 10)\n",
    "        print(\"-\" * 10 +  args.identifier + \"-\" * 10)\n",
    "        print(\"-\" * 10 + \"-\" * len(args.identifier) + \"-\" * 10)\n",
    "    \n",
    "    print(\"Rank\",hvd.rank(),\"Local Rank\", hvd.local_rank())\n",
    "    \n",
    "    #adapter of commandline parameters\n",
    "\n",
    "    modelPath = '/projects/p_electron/stiller/schrodinger/thesis/models/' + args.identifier + '/'\n",
    "    logdir = '/projects/p_electron/stiller/schrodinger/thesis/tensorboard/' + args.identifier + '/'\n",
    "    batchSizePDE = args.batchsize\n",
    "    useGPU = True\n",
    "    numBatches = args.numBatches\n",
    "    initSize = args.initSize\n",
    "    numLayers = args.numLayers\n",
    "    numFeatures = args.numFeatures\n",
    "    numEpochsSolution = args.epochsSolution\n",
    "    numEpochsPDE = args.epochsPDE\n",
    "    activateEnergyLoss = args.energyLoss\n",
    "    pretraining = args.pretraining\n",
    "    #postprocessing = args.postprocessing\n",
    "\n",
    "    #create modelpath\n",
    "    if hvd.rank() == 0:\n",
    "        pathlib.Path(modelPath).mkdir(parents=True, exist_ok=True) \n",
    "    # create logWriter\n",
    "    log_writer = SummaryWriter(logdir) if hvd.rank() == 0 else None\n",
    "\n",
    "    # create dataset\n",
    "    ds = SchrodingerEquationDataset(pData, coordinateSystem, numOfEnergySamplingPointsX, numOfEnergySamplingPointsY, initSize, numBatches, batchSizePDE, shuffle=True, useGPU=True,do_lhs=args.lhs)\n",
    "\n",
    "    # Partition dataset among workers using DistributedSampler\n",
    "    train_sampler = torch.utils.data.distributed.DistributedSampler(ds, num_replicas=hvd.size(), rank=hvd.rank())\n",
    "    train_loader = torch.utils.data.DataLoader(ds, batch_size=1, sampler=train_sampler)\n",
    "\n",
    "    activation = torch.tanh\n",
    "\n",
    "    print(\"Memory Allocated before\",torch.cuda.memory_allocated('cuda:0') / 1e9)\n",
    "    model = SchrodingerNet(numLayers, numFeatures, ds.lb, ds.ub, numOfEnergySamplingPointsX, numOfEnergySamplingPointsY, torch.tanh).cuda()\n",
    "    print(\"Memory Allocated after\",torch.cuda.memory_allocated('cuda:0') / 1e9)\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=3e-5)\n",
    "    optimizer = hvd.DistributedOptimizer(optimizer,\n",
    "                                         named_parameters=model.named_parameters(),\n",
    "                                         backward_passes_per_step=1)\n",
    "\n",
    "    if pretraining:\n",
    "        for epoch in range(numEpochsSolution):\n",
    "            for x0, y0, t0, Ex_u, Ex_v, xf, yf, tf, xe, ye, te in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "                # calculate loss\n",
    "                loss = model.solution_loss(x0, y0, t0, Ex_u, Ex_v)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            if epoch % 5 == 0:\n",
    "                print(\"Loss at Epoch \" + str(epoch) + \": \" + str(loss.item()))\n",
    "                sys.stdout.flush()\n",
    "                if log_writer:\n",
    "                    log_writer.add_scalar(\"Initital Loss\",loss.item(),epoch)\n",
    "\n",
    "\n",
    "    # save model after initial training\n",
    "    if log_writer:\n",
    "        state = {\n",
    "        'model': model.state_dict(),\n",
    "        'optimizer': optimizer.state_dict()}\n",
    "        torch.save(state, modelPath + 'model_init_' + str(0))\n",
    "\n",
    "    for paramGroup in optimizer.param_groups:\n",
    "        paramGroup['lr'] = 7e-6\n",
    "\n",
    "    for epoch in range(numEpochsPDE):\n",
    "\n",
    "        for x0, y0, t0, Ex_u, Ex_v, xf, yf, tf, xe, ye, te in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # calculate loss\n",
    "            \n",
    "            loss = model.ec_pde_loss(x0,\n",
    "                                     y0,\n",
    "                                     t0,\n",
    "                                     Ex_u,\n",
    "                                     Ex_v,\n",
    "                                     xf,\n",
    "                                     yf,\n",
    "                                     tf,\n",
    "                                     xe,\n",
    "                                     ye,\n",
    "                                     te,\n",
    "                                     1.,\n",
    "                                     numOfEnergySamplingPointsX,\n",
    "                                     numOfEnergySamplingPointsY,\n",
    "                                     activateEnergyLoss,\n",
    "                                     args.alpha)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        if epoch % 30 == 0:\n",
    "            writeIntermediateState(0, model, epoch, nx, ny, log_writer,coordinateSystem)\n",
    "            writeIntermediateState(250, model, epoch, nx, ny, log_writer,coordinateSystem)\n",
    "            writeIntermediateState(500, model, epoch, nx, ny, log_writer,coordinateSystem)\n",
    "            writeIntermediateState(750, model, epoch, nx, ny, log_writer,coordinateSystem)\n",
    "            writeIntermediateState(1000, model, epoch, nx, ny, log_writer,coordinateSystem)\n",
    "            writeValidationLoss(model, log_writer, 250, epoch,coordinateSystem)\n",
    "            writeValidationLoss(model, log_writer, 500, epoch,coordinateSystem)\n",
    "            writeValidationLoss(model, log_writer, 750, epoch,coordinateSystem)\n",
    "            writeValidationLoss(model, log_writer, 1000, epoch,coordinateSystem)\n",
    "            sys.stdout.flush()\n",
    "\n",
    "            print(\"PDE Loss at Epoch: \", epoch + 1, loss.item())\n",
    "            if log_writer:\n",
    "                log_writer.add_histogram('First Layer Grads', model.lin_layers[0].weight.grad.view(-1, 1), epoch)\n",
    "                save_checkpoint(model, optimizer, modelPath, epoch)\n",
    "\n",
    "    if log_writer:\n",
    "        hParams = {'numLayers': numLayers,\n",
    "                   'numFeatures': numFeatures,\n",
    "                   'ResidualPoints': numBatches * batchSizePDE,\n",
    "                   'alpha':args.alpha,\n",
    "                   'ELoss': activateEnergyLoss}\n",
    "\n",
    "        valLoss0 = valLoss(model, 0, coordinateSystem)\n",
    "        valLoss250 = valLoss(model, 250, coordinateSystem)\n",
    "        valLoss500 = valLoss(model, 500, coordinateSystem)\n",
    "\n",
    "        metric = {'hparam/SimLoss': loss.item(),\n",
    "                  'hparam/valLoss0': valLoss0,\n",
    "                  'hparam/valLoss250': valLoss250,\n",
    "                  'hparam/valLoss500': valLoss500}\n",
    "\n",
    "        log_writer.add_hparams(hParams, metric)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
